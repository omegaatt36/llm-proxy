services:
  llm-proxy:
    container_name: llm-proxy
    restart: always
    build:
      context: .
    ports:
      - 4000:4000
    volumes:
      - ./config.yaml:/config.yaml
